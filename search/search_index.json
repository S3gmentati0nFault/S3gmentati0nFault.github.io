{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome on my portfolio website!</p> <p>I'm a computer science student at the end of my master studies at Universit\u00e0 degli studi di Milano, I started the master with the intention of exploring the field of distributed systems and cloud computing, I am now moving towards the field of applied machine learning after the course of Machine Learning for Physics held by professor Tilman Plehn at Karl Ruprecht university of Heidelberg.</p> <p>I am in the process of starting my master Thesis titled \"Supervised machine learning techniques for quench detection in superconductors\" accompanied by professors Dario Malchiodi and Lucio Rossi.</p>  What am I looking for?  <p>My university journey is now coming to an end, a recurring thought lately has been:\"What do I want from my future?\"</p> <p>At the moment I am exploring the possibilities of a PhD in computer science applied to the field of physics, I am very interested in:</p> <ul> <li> <p>GPU computing or efficient algorithm design (both sequential and parallel)</p> </li> <li> <p>Machine learning, deep learning and data science applied to complex scientific fields</p> </li> </ul> <p>Alternatively any job offer is welcome! Do you want to contact me? You can reach me through:</p> <ul> <li> <p>Email</p> </li> <li> <p>Linkedin</p> </li> <li> <p>Telegram</p> </li> </ul>"},{"location":"algoweb/readme/","title":"Web algorithmics","text":"<p>The project can be found on Github (Algoweb project)</p> <p>This project was written mainly in LaTeX.</p> Introduction <p>Review of the lecture notes for the course of Web algorithmics, held by professor Sebastiano Vigna at Universit\u00e0 degli studi di Milano, the lecture notes are in italian and are updated to the end of last year.</p> <p>They are still a very viable option for all the students that take the course.</p> <p>I consider this project to be a good showcase of my abilities in the field of LaTeX typesetting, if compared to my bachelor thesis I think that this project is more polished and refined.</p> <p>Download Algoweb 2.0</p>"},{"location":"autoencoders/readme/","title":"Anomaly detection","text":"<p>The project can be found on Github (Autoencoders project).</p> <p>This project was written mainly in Python using Jupyter notebooks.</p> Introduction <p>I did this project alongside Mario Massimo during my stay in Heidelberg for the course of Machine Learning and Physics held by professor Tilman Plehn. The project aimed at comparing performance for two different machine learning architectures, the first being an MLP based autoencoder and the second being a CNN based autoencoder, in the field of anomaly detection.</p> <p>The dataset came from the professor and a given preprocessing step was applied to turn CMS measurements into 40x40 images.</p> <p>The task at hand was: given the dataset, containing two different types of jets (Quantum ChromoDynamics and Top), use one of the two jets as signal and the other as anomaly.</p> <p>The following image is taken from the representation of two different jets inside of the dataset, one is a Top jet and the other is a QCD jet. A straightforward consequence of the three-pronged structure of top jets is going to be that using the spatial information to distinguish them from the anomaly (QCD jets) is not going to be a great idea, and that is because QCD jets can be seen as a top jet whose prongs are extremely close together.</p> Top (left) vs QCD (left) jets <p>A round of reconstruction can be seen in the following image, the process was done using the MLP autoencoder trained to recognize Top jets as signal and QCD jets as anomaly.</p> <p>As it can be clearly seen the reconstruction procedure is far from perfect, due to a very high amount of background noise, but the autoencoder is able to recognize and reconstruct the principal spatial features of both the signal and the anomaly. This proves that the autoencoder is unable to find the anomaly (in this case the QCD) since it reconstructs it almost perfectly, as if it was a Top jet.</p> <p>The code can be found on my github repository and down below I provide downloads for the compressed dataset, an HTML version of the notebook with all the outputs and the requirements sheet.</p> <p>Download sheet requirements</p> <p>Download the compressed dataset</p> <p>Download the HTML notebook</p>"},{"location":"bachelor/readme/","title":"Bachelor Thesis","text":"<p>The project can be found on Github (Bachelor project)</p> <p>This project was written mainly in:</p> <ul> <li>Java for the backend</li> <li>Javascript for the frontend</li> <li>LaTeX for the final thesis</li> </ul>  Introduction  <p>My bachelor project consisted in the development of a microservice-based web application to securely handle sensitive user data for a company. To each user are associated: private information, soft skills, hard skills and a role. The application was developed using Spring Boot, ReactJS and MySQL databases. The project was presented in July 2021.</p> <p>The project consisted of six components:</p> <ul> <li>Frontend - Developed using React.js</li> </ul> <p>The following components developed using Spring Boot:</p> <ul> <li> <p>Gateway - The entry point of the application</p> </li> <li> <p>Security</p> </li> <li> <p>Backend</p> </li> </ul> <p>And then two MySQL databases:</p> <ul> <li> <p>Security database - which handles only the basic user information (email, password, isEnabled)</p> </li> <li> <p>Primary database - which handles the rest of the user information</p> </li> </ul> <p>All of the components were handled using microservices which were built using both Dockerfile and Docker-compose. The UI of the project was developed using ReactJS and a sample is shown in the following figure.</p> Home of the user view  Functionalities  <p>The application allows the generic user to:</p> <ul> <li> <p>Register</p> </li> <li> <p>Login</p> </li> <li> <p>Update their information (both personal and linked to hard and soft skills that they might have)</p> </li> </ul> <p>The top level user is able to:</p> <ul> <li> <p>Cancel users</p> </li> <li> <p>Search any user inside the database and view or modify their information</p> </li> <li> <p>Disable users</p> </li> </ul> <p>The docker-compose.yaml file was written as follows, since the application was only for demo pourposes the database passwords were as easy as possible and no information was encrypted.</p> <pre><code>version: \"3.9\"\n\nservices:\n  userdb:\n    container_name: user_database\n    image: mysql\n    restart: always\n    environment:\n      - MYSQL_ROOT_PASSWORD=password\n      - MYSQL_DATABASE=database-utenti\n    ports:\n      - \"3307:3306\"\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p password\"]\n      timeout: 20s\n      retries: 15\n\n  securitydb:\n    container_name: security_database\n    image: mysql\n    restart: always\n    environment:\n      - MYSQL_ROOT_PASSWORD=password\n      - MYSQL_DATABASE=database-sicurezza\n    ports:\n      - \"3308:3306\"\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p password\"]\n      timeout: 15s\n      retries: 15\n\n  blue-whale:\n    container_name: gatewayB\n    build:\n      context: ./backend-gateway\n      dockerfile: \"Dockerfile\"\n    ports:\n      - \"8080:8080\"\n\n  sleepin-cat:\n    container_name: usersB\n    build:\n      context: ./backend-gestione-utenti\n      dockerfile: \"Dockerfile\"\n    depends_on:\n      userdb:\n        condition: service_healthy\n    ports:\n      - \"8082:8082\"\n\n  honeybear:\n    container_name: securityB\n    build:\n      context: ./backend-login\n      dockerfile: \"Dockerfile\"\n    depends_on:\n      securitydb:\n        condition: service_healthy\n    ports:\n      - \"8081:8081\"\n\n  frontend:\n    container_name: frontend\n    build:\n      context: ./frontend\n      dockerfile: \"Dockerfile\"\n    ports:\n      - \"3000:3000\"\n</code></pre> <p>The final thesis for the project can be found on Github as well as the presentation I put together for the final bachelor thesis discussion. The download links are the following:</p> <p>Download last version of the thesis</p> <p>Download last version of the presentation</p>"},{"location":"boruvka/readme/","title":"Efficient solution for MST computation on sparse graphs","text":"<p>The project can be found on Github (GPU-project).</p> <p>This project was written mainly in C++ and CUDA C.</p>"},{"location":"boruvka/readme/#introduction","title":"Introduction","text":"<p>This project was developed for the exam of GPU computing held by professor Giuliano Grossi at Universit\u00e0 degli studi di Milano, I chose to analyze this problem because I had already considered one of its solutions for the Programming Languages course during my bachelor.</p>"},{"location":"boruvka/readme/#background","title":"Background","text":"<p>The project is mainly based on the implementation proposed by the University of Minho \"A generic and highly efficient parallel variant of Boruvka's algorithm\". The performance measurements register an uplift that is comparable to the one computed in the original paper, all of the benchmarks have been conducted on sparse graphs because for a series of reasons: </p> <ol> <li> <p>Boruvka's algorithm performs better on sparse graphs.</p> </li> <li> <p>Considering the approach proposed in the original paper it's apparent that it was meant to work    at peak performance only when sparse graphs were considered.</p> </li> </ol>"},{"location":"boruvka/readme/#the-algorithm","title":"The algorithm","text":"<p>Given a graph \\(\\mathcal{G}(E, V)\\) the CPU version of Boruvka solver has a computational complexity of \\(\\mathcal{O}(m\\cdot\\log{n})\\) where \\(m\\) is the size of the edge set \\(E\\) and \\(n\\) is the size of the vertex set \\(V\\). The reason why Boruvka's approach is chosen more often compared to Prim's and Kruscal's counterparts is because it's more indicated for any parallel approach. In general, a parallel approach based on Boruvka can be divided in the following operations:</p> <ul> <li> <p>Choose the lightest edge</p> </li> <li> <p>Find the root of the connected component</p> </li> <li> <p>Rename the supervertices obtained by doing component merge</p> </li> <li> <p>Graph contraction</p> </li> </ul> <p>All of these operations are performed until the graph has size \\(1\\), which means that all of the graph was contracted in one supervertex.</p> <p>The particular implementation followed by the colleagues at Minho university is to compute each one of these actions as a single kernel, one thread per vertex, since there is no dependence between vertices the result is that the computation can be carried out very efficiently as long as the neighbourhood for every vertex has a reasonable size. Almost no synchronization is required (only inside the exclusive scan operation) and resorting to atomic oeprations is not the norm, therefore we have an approach that is almost lock-free and able to perform at a high level on most benchmarking instances.</p>"},{"location":"boruvka/readme/#performance","title":"Performance","text":"<p>The algorithm was tested through Google Colab online development environment using their T4 GPU alongside \\(12\\) GB of system memory two virtual cores taken from an undescriptive Xeon CPU equipped with \\(3\\) MB of cache. Benchmarking instances were taken from the 9th DIMACS (DIscrete MAthematics &amp; theoretical Computer Science center) challenge meant to try and solve the Shortest Path problem efficiently.</p> Chosen benchmarking suite <p>On these benchmarks I registered a GPU uplift ranging between \\(30\\) and \\(180\\) times depending on the CPU and GPU implementation considered.</p>"},{"location":"boruvka/readme/#conclusions","title":"Conclusions","text":"<p>There is more that still needs to be discovered and since MST solvers are the basis for many other algorithm implementations fast is never too fast. I expect more work to be done in the field of parallel MST computation, especially trying to find novel approaches that do not necessarily use graph contraction to carry out the computation therefore having stronger performance in the field of dense graphs manipulation. As far as contraction-based techniques are concerned, I would be interested in seeing whether a fully scan-based implementation suffers as much as hypotheses say due to the necessary amounts of synchronization to make sure that all the threads have a consistent view of memory.</p> <p>The full pdf for \"A generic and highly efficient parallel variant for Boruvka's algorithm\" can be found here: original paper</p> <p>The full pdf report for my project can be found here: final report</p>"},{"location":"cpp/readme/","title":"C++ programming project","text":"<p>The project can be found on Github (C++ programming project)</p> <p>This project was written mainly in C++.</p> Introduction <p>The project was assigned for the course of C++ programming at Universit\u00e0 degli studi Milano Bicocca held by professor Gianluigi Ciocca.</p> <p>The project consisted of two different assignements, one of common C++ programming in the field of data structures and the other required the implementation of a simple GUI using QT.</p> <p>Down below you can find the description of the two assignements alongside a download of the documentation provided with the source code and generated using doxygen.</p> <p>Download the project assignement</p> <p>Download the documentation</p>"},{"location":"deployment_of_llms_in_6G_networks/readme/","title":"Deployment of LLMs at the edge of the 6G network","text":"<p>The repository for this project can be found on Github (CCT-project)</p> <p>This project was written mainly in LaTeX.</p>  Introduction  <p>This project was a research paper written for the course of Cloud Computing Technologies held by Professors Claudio Ardagna and Marco Anisetti at Universit\u00e0 degli studi di Milano.</p> <p>The idea came from me, and originated from a question I saw asked in a paper: \"What if 5G was enough? Do we really need 6G?\".</p> <p>The point of the paper was not to answer this question but to go through the main aspects that have been identified for the next mobile communication standards, therefore the paper is substantially meant as a paper-review of the current research fields linked to 6G. I concentrated on the concept of creating a fusion of 6G and AI in the form of LLMs and I identified some problems and some potential solutions to the problem of doing such a deployment.</p> <p>In the paper I go through the following steps:</p> <ul> <li> <p>Introduction.</p> </li> <li> <p>6G overview: using a whitepaper from Nokia, I go through the 6 key aspect of the new 6G   communication standard putting more emphasis on the fact that 6G should be a network that is shaped to the user's need and liking and therefore it's going to make heavy use of AI approaches like LLMs.</p> </li> <li> <p>Opportunities: I use this section to briefly expose opportunities that   have been identified in the literature and then I move to explaining my idea of the architecture,   that builds upon the spectrum distribution showed in the previous section.</p> </li> <li> <p>Technical limitations: I use this section to expose some of the evident problems connected to   the need of having LLMs stored in the network in locations that are as close as possible to the end users and I also propose some solutions found in literature in the field of distributed learning (Federated Learning, Split Learning and LoRA).</p> </li> </ul> <p>In the end I just draw some conclusions and propose some future work that could be done in the field.</p> <p>The pdf for both the paper and the presentation can be found at the links below</p> <p>Download the paper</p> <p>Download the presentation</p>"},{"location":"greenfield/readme/","title":"Greenfield","text":"Greenfield <p>The project can be found on Github (Greenfield project)</p> <p>This project was written mainly in Java.</p> Introduction <p>In the repository linked above is contained all of the code for the project of Distributed and Pervasive Systems held by professors Claudio Bettini and Luca Arrota at Universit\u00e0 degli Studi di Milano, the project was presented in September 2023.</p> <p>Before beginning the explanation I would like to point out that throughout this file I will generally talk about robots, processes and threads really freely, considering the scope of the project they are the same thing.</p> <p>In the project we were required to simulate a smart city's cleaning system, we had a set of processes roaming around and collecting pollution data that were autonomously sent to a server, each of the robots had a 10 percent probability of having problems and needing to go to a mechanic for repairs. The mechanic was able to handle one repair process at a time thus it was necessary to handle different requests arriving at the mechanic in parallel. The full project description can be found in the <code>./project_assignement</code> folder.</p> Structure of the solution <p>The following is the list of all the classes that I chose to implement for this project</p> <ul> <li>Main</li> <li>Admin Client</li> <li>Admin Server<ul> <li>Server Rest Interface</li> <li>MQTT Subscriber</li> <li>Bot Positions</li> <li>Average List</li> </ul> </li> <li>Cleaning Bot<ul> <li>Bot Services</li> <li>Service Comparator</li> <li>Waiting Thread</li> <li>Bot Thread</li> <li>Eliminator Thread</li> <li>Fix Helper Thread</li> <li>GRPC Services Thread (GRPC server)</li> <li>Input Thread</li> <li>Maintenance Thread</li> <li>Measurement Gathering Thread</li> <li>Mutual Exclusion Thread</li> <li>Pollution Sensor Thread</li> <li>Quit Helper Thread</li> <li>Bot Identity Comparator</li> <li>Bot Utilities</li> <li>Comm Pair</li> <li>Measurement Buffer</li> <li>Position</li> </ul> </li> <li>Extra<ul> <li>Atomic Counter</li> <li>Atomic Flag</li> <li>Logger</li> <li>Thread Safe data structure wrapper</li> </ul> </li> <li>Simulator Code</li> <li>Variables</li> </ul> <p>My implementation is quite thread heavy, but I wanted to really experiment as much as possible with it, to get to know and understand how threads work and how to control them while accessing information together.</p> Operations <p>In the following I will discuss my implementation of the different operations.</p> Join <p>When a new process is created it starts the initiator thread, which is simply a thread that instanciates and starts all of the necessary services (e.g. the GRPC Services Thread). in the meanwhile it requests the server to join the network, the join operation currently consists of two parts:</p> <ul> <li>Addition of the new robot to the Admin Server's local structure</li> <li>Communication of personal data (i.e. an instance of the <code>BotIdentity</code> class) to all of the robots in the network</li> </ul> <p>The GRPC communication is asynchronous, and I decided to do two different HTTP requests (check ID availability, communicate my existence to the network) to highlight the difference between the two tasks.</p> <p>The position in the city is chosen by the Admin Server simply by checking which district has the lowest current density. Originally it was supposed to pick a random district uniformly, while the solution would tend to a stable distribution (if enough processes were initialized), it would not be stable for the majority of the low density cases.</p> <p>The flow diagram for the operation is shown below</p> Join operation flow diagram Comm Pair <p>The <code>Comm Pair</code> class is a simple toy I came up with, it's nothing more than a pair containing a <code>ManagedChannel</code> and a <code>GRPCStub</code>. The idea behind it is simply to keep on recycling open stubs and channels; thus saving the resources necessary to open a new one each and every time communication has to take place. Since the project is required to rely heavily on GRPC communication.</p> <p>Comm Pairs are clustered into <code>ThreadSafeHashMaps</code>, each of the pairs is associated to the hash of the <code>BotIdentity</code> the <code>ManagedChannel</code> connects to.</p> Maintenance process <p>The maintenance process is handled by two different threads, one deals with checking whether the robot should go under maintenance or not, the other is built and initialized when the robot undergoes maintenance and handles communication and the maintenance procedure; therefore the maintenance process is handled by a new thread.</p> <p>Any operation involving the network is done by taking a snapshot of the current robot distribution. The GRPC is asynchronous and carried out in parallel, any removals necessary are postponed until the maintenance process is over, thus the removal and stabilization (which do not come cheap) are done at most once per process.</p> Maintenance operation flow diagram Pollution measurements <p>Pollution measurements (more about this later) stop during maintenance, originally they would still be sent, but I decided against it becasue since the robot is under maintenance it would be sending to the server data that make no sense.</p> Removal <p>The solution I implemented to handle removals is overengineered and overkill for the job and the setup of the project.</p> <p>The reason behind it is that it was originally thought to straighten even the worst distributions (e.g. 1-6, 2-0, 3-0, 4-0), keep in mind that I originally placed robots in the city randomly</p> <p>The elimination works this way:</p> <ul> <li>I remove mentions of the dead robot from the local machine.</li> <li>I contact the Admin Server to let him know that there are dead robots in the city.</li> <li>Contact the other robots in the network to remove the references to dead robots from their systems.</li> <li>Stabilize the data structure.</li> </ul> <p>The flow diagram for the operation is the following</p> The first part of the removal operation <p>The eventual positional change required to stabilize the robot distribution (we want the distribution of the robots in the network to be uniform after a removal).</p> Position update procedure <p>It's important to mention a couple of details</p> GRPC calls <p>For the elimination procedure, two different GRPC procedures have been called:</p> <ul> <li><code>moveRequest</code>: which is used by the robot dealing with the elimination process to tell another robot to move away from a district.</li> <li><code>positionModificationRequest</code>: which is more like a notification, when a robot moves to another district it computes a random position inside that district and lets every robot in the network know that its position is changed.</li> </ul> <p>Whenever a robot receives a <code>moveRequest</code> the thread waits until the position is changed and the robots in the network have been notified to perform the <code>onComplete</code> and <code>onNext</code> operations.</p> How robots are chosen <p>During the elimination procedure it's important to make sure that everyone is on the same page, to be sure about that I created a setup phase before stabilization where an auxiliary data structure is built.</p> <p>I decided to use a list of Priority Queues with a specific Comparator that allows me to do sorting on the robots by <code>ID</code>. The stabilization is later carried out just by moving around the top of the queues.</p> Pollution sensor <p>The pollution sensor is composed by four different entities:</p> <ul> <li>Simulator.</li> <li>Measurement Buffer.</li> <li>Measurement Gathering Thread.</li> <li>Pollution Sensor Thread.</li> </ul> <p>The Measurement Buffer implements a read/write cycle depending on the available size of the buffer. The cycle works unless the robot is on maintenance.</p> <p>The Measurement Gathering Thread keeps averages in memory until the Pollution Sensor Thread comes and takes them from him. This Thread, the same way the other did, stays on hold until the maintenance process is done.</p> <p>The Pollution Sensor Thread is the timer of the pipeline and handles MQTT broadcasting. Each MQTT broadcast will be at most 25 seconds apart from the one before, that is because I wanted to simulate the fact that a robot might be undergoing maintenance, normally the measurement timer pings the server every 15 seconds.</p> FIX and QUIT commands <p>Both FIX and QUIT commands are being handled through dedicated threads, created once the commands are typed. To be fair the existence of a specialized thread just to send a process to the mechanic is really useless and could be avoided altogether. The QUIT command is a bit more complicated and having a thread in that case is a bit more useful, because if it has to wait doesn't lock the entirety of the input pipeline, but could still be removed in favour of a synchronized function.</p> <p>I wrote a small document that goes through everything that I mention here plus some more details and charts, it can be downloaded from here.</p> <p>Download the project presentation</p>"},{"location":"me/curriculum/","title":"Curriculum","text":"<p>Currently working on having a link down here to download the latest version of the curriculum vitae pdf file.</p> <p>In the meantime, this page acts as a web-based version of my curriculum vitae. It is updated regularly, so feel free to check back for the latest version.</p>  Contact Information  <p>You can always contact me using the following channels:</p> alexbgtt@gmail.com Linkedin  Education  <ul> <li> <p>Master student in Computer Science at the Universit\u00e0 degli studi di Milano (2022 - present)</p> </li> <li> <p>Erasmus student in Computer Science, Physics and Scientific Computing at Karl Ruprecht University of Heidelberg (Sep 2023 - Mar 2024)</p> </li> <li> <p>Bachelor's degree in Computer Science at the Universit\u00e0 degli studi di Milano Bicocca (2020 - 2022)</p> </li> <li> <p>Bachelor studente in Computer Engineering at Politecnico di Milano (2018 - 2020)</p> </li> </ul>  Previous work experiences  <ul> <li> <p>Currently working as a tutor for international students at the Universit\u00e0 degli studi di Milano (2024 - present)</p> </li> <li> <p>Worked as a waiter for La Birrofila brewpub in Milan (May 2022 - Sep 2022)</p> </li> <li> <p>Did an internship as programmer for the bachelor thesis while in Universit\u00e0 degli studi di Milano Bicocca for Certimeter Group (Feb 2021 - Jun 2021)</p> </li> <li> <p>Worked as a scrutineer for various elections in the city of Milan</p> </li> <li> <p>Worked as a private tutor for various students helping them facing exams and tests in various subjects (English, Mathematics, Electromagnetism, Physics, Computer Science, ...)</p> </li> </ul>  Projects  <p>Instead of listing every project I have done here is a selection of my top 5 most important projects in no particular order</p> <ul> <li> <p>Efficient solution for MST   computation on sparse graphs</p> </li> <li> <p>Anomaly detection for CMS   measurements using Autoencoders</p> </li> <li> <p>Greenfield</p> </li> <li> <p>A secure microservice based   web-application to handle the data of employees</p> </li> <li> <p>Web algorithmics lecture notes</p> </li> </ul>  Laguages  <ul> <li> <p>Italian: native speaker</p> </li> <li> <p>English: C1</p> </li> </ul> <p>The english level was certified many years ago through a First for english test and the result was B2. Since then, I have done a series of simpler tests (entrance english test for the university) that are non certifying and provided varying results (between C1 and C2). I am confident that the current level is C1.</p> <ul> <li>Spanish: A2</li> </ul> <p>Studied spanish many years ago but can still understand, read and speak about myself and some other topics. Some work would be required to reach a good level of proficiency.</p> <p>Interests:</p> <ul> <li> <p>German</p> </li> <li> <p>French</p> </li> </ul>  Programming languages  <p>To trace a parallel with the spoken languages I have taken a selection of the programming languages I feel most comfortable with and graded my knowledge based on the number of projects I have done with them, the years I have been using them for and the level of confidence I feel when coming back to them; the measurement is, of course, completely subjective,</p> <ul> <li>Java: C1</li> </ul> <p>I know how to work with Java, I used it a lot and I have done all of the introductory courses for   programming with it and I developed the backend for my thesis with it. Furthermore I know how to   work with Threads and concurrency.</p> <ul> <li>Python: B2</li> </ul> <p>I am using Python currently for my master thesis, I never really studied the basis but I moved   directly to the use of complex libraries like Numpy, Pandas and Sklearn for Machine Learning and   data analysis.</p> <ul> <li>C, C++, Cuda C: B2</li> </ul> <p>C was the first programming language I ever learned and C++ adopted me, I know the older standards   for C++ but I would like to get to know some of the newer inventions for this language. On the   side I also got to experiment with the Cuda C framework for my GPU computing project</p> <p>Interests:</p> <ul> <li> <p>Go</p> </li> <li> <p>Rust</p> </li> </ul>  Frameworks, software and operating systems  <p>In the following I will go over some of the software and frameworks that I use the most and I have used in my private or university projects.</p> Nvim <p>Recently discovered the power of this text editor and I am currently using it for most of my projects, still trying to get the hang of it though.</p> Git <p>Wouldn't consider myself proficient in the usage of git, but I can use it comfortably to manage my projects and work with other people.</p> LaTeX <p>I have been using LaTeX for many years and for many different projects, again, I would not define myself an expert in the field, but I can use it comfortably to manage all the documents that require a more professional look.</p> Linux <p>I have been a die hard fan of the Linux ecosystem for many years now, I have been using many different distributions (from Void to Debian to Manjaro to Ubuntu) and I always learned something while breaking the operating system.</p> <p>I am currently rocking a single boot Pop-OS! installation of my personal tower with which I do all of my work.</p> Mac OS <p>I have been using a 2014 Macbook Pro since 2022 and I am quite happy with it, I find the operating system amazing and the idea that I can handle all of my packages via terminal through the brew package manager is amazing.</p> Windows <p>I have used Windows for many years, I used to be comfortable with it until I started my university journey, had to switch to Linux to make sure I could work with things like the C compiler and other tools without headaches.</p>"},{"location":"me/erasmus/","title":"Erasmus","text":"<p>During my master studies I decided to try and do an Erasmus experience, due to the hard conditions in which I were during the last years of my bachelor degree I was not in a space in which I could decide to go on an Erasmus adventure. During the master I had the time and the resources to invest in such an experience.</p> <p>I decided to go to Karl Ruprecht university of Heidelberg, in Germany, and, due to an increasing interest I have had for a while towards the field of physics, I decided to challenge myself with a series of very hard courses:</p> <ul> <li> <p>Machine learning and Physics - A course about machine learning approaches applied to high energy physics.</p> </li> <li> <p>Astrophysics seminar - For which I presented new ways of handling galaxy simulations using   hydrodynamics</p> </li> <li> <p>Condensed Matter</p> </li> <li> <p>Discrete structures 1 - A course about graph theory from the department of mathematics.</p> </li> <li> <p>GPU computing</p> </li> </ul> <p>Due to how hard the exams resulted I ended up with only the Machine learning and Physics exam passed, but the experience completely changed me and taught me how to adapt to an ever changing situation.</p> <p>Let me explain.</p> <p>Heidelberg university does not own student homes, everything is done through an external company called Studierendenwerk Heidelberg, even though the company is completely independent from the university, when the request is sent to receive a place in a student home it's also required of the prospect student to send an email to the university (why? Who knows). If the email is not sent the prospect student is not elegible to receive a place in a student home.</p> <p>Unfortunately the two systems do not talk to each other, therefore if the student doesn't send the email the database from Studierendenwerk will never be notified and said student will be waiting aimlessly for a place in a student home.</p> <p>I was said student.</p> <p>I arrived in Heidelberg on the 29th of september and I began looking for a place using every weapon and technique that I could possibly think of, I asked friends I made at the university, facebook groups and I tried many other solutions (all while waiting for a response from the Studierendenwerk, I still had no idea that I was not elegible for a place).</p> <p>On day 5 or 6 (can't really remember) I decided to go to Studierendenwerk HQ to ask about my housing request, that was when I discovered I was not elegible and I thought that my Erasmus was ruined (the housing market in Heidelberg, just like many other university cities can be best described by picturing a jungle full of fearsome predators).</p> <p>After two, very expensive, weeks in a hostel I was about to wave the white flag and go back to Italy.</p> <p>I tried one last desperate attempt and, incredibly, thanks to a friend (Ujjwal Yadav) who gave me the email of a person that could help me, I was lucky enough to find a place in a student home, even though it was outside of the city.</p> <p>After spending another week at another friend's place I was able to move into my own house that I shared with 3 other people and I could finally start my Erasmus experience.</p> <p></p>"},{"location":"me/passions/","title":"Passions","text":"<p>I have always been easily impressed by people and if I came across anyone with a very strong drive in some area I would easily be captivated and start gaining interest in that area as well, this is why I have tried many different hobbies and, to this day, I have many different interests that I would like to explore further if I had the time.</p>  Movies  <p>Movies are probably the thing that I like the most at the moment, leave me in front of a good TV or at the movie theater and you will find me there. I am trying to build a movie culture that is as broad as possible.</p> <p>My favourite new director is Denis Villeneuve, I think that his movies have an incredible feeling, he is very talented in both directing and photography. My favourite movie of his might be Blade Runner 2049.</p> <p>My favourite \"vintage\" director is Stanley Kubrick, I have seen most of his movies and I do think that his works are simply timeless and will always be relevant and impressive. My favourite movie of his is The Shining.</p>  Climbing  <p>I really like climbing, I have been doing it for around half a year and I feel very comfortable while bouldering, top roping and lead climbing are still a bit out of my comfort zone but my objective is to be able to do at least one easy outdoors climbing route before the end of the year. I am trying to get better at it and until now I was able to always train between one and two times a week.</p>  Music  <p>I always loved music, I played bass guitar for a couple of years and I would say that I have a good enough musical culture, one of my favourite genres is nu-metal, one of my favourite bands is Linkin Park. Anything progressive, anything industrial, anything more rock or pop-ish is also up my alley.</p> <p></p>  Photography  <p>I have always been fascinated by photography and I am always attracted by the idea of getting a good shot, there was a time when I was very into it and taking a lot of pictures with a Canon Eos 60D, working on the shots and trying to get better at it.</p> <p>I still own a camera, but I do not use it anymore I usually just take pictures with my phone and I take care that the results are as good as they can possibly be. Some of my shots have been chosen to participate in some contests and I have taken pictures for a wedding in 2018.</p>  Basketball  <p>I played basketball for ten years as a kid and the passion never really went away, I have always been into the NBA and I followed it (sometimes more, sometimes less) for the last seven years. Go OKC!</p>  Reading  <p>I have never been a reader in my life, always struggled with the idea of reading a book, but when I started going to university I built a habit and I found a way of keeping me into the loop. I am surely not the fastest reader, I am not one of those people that can read 50 books a year, but I do enjoy reading and I do it when I can and when I feel like it. Currently trying to read more classics.</p> <p>My favourite book? Hitchhiker's Guide to the Galaxy, by Douglas Adams.</p>"},{"location":"me/polimi/","title":"Polimi","text":"<p>I began my bachelor studies pursuing a degree in Computer engineering at Politecnico di Milano (Polimi). Unfortunately, due to the covid pandemic in 2020 and family hardships I chose to change university.</p> <p>During the first two years of studying I went through the following exams:</p> <ul> <li> <p>Calculus 1 and 2</p> </li> <li> <p>Algebra</p> </li> <li> <p>Advanced algebra and logic</p> </li> <li> <p>Foundamentals of Computer Science</p> </li> <li> <p>Architectures and Operating systems</p> </li> <li> <p>Foundamentals of control systems</p> </li> <li> <p>Physics 1</p> </li> <li> <p>Chemistry</p> </li> <li> <p>Algorithms and Data structures</p> </li> </ul>"},{"location":"me/projects/","title":"Other projects","text":"Introduction <p>I always wanted to try and create a community to gather, virtually or physically, and share passions and ideas. I have been involved or started myself a series of projects that were meant to bring people together but most of them never really hit it off, some of the most succesfull are surely the ones shown below.</p> Podcast <p>At the end of 2021 me and my good friend Alin Tomulet decided to start a joint project to talk about cool stuff on the air. I always wanted to do something radio-like but all the previous projects I tried did non work out.</p> <p>From our joint passion the project for A Boring podcast was born.</p> <p>we started recording episodes in my room and we were able to invite some friends over as guests after just a couple of episodes. all of the episodes were around the hour mark and we usually talked about topics that were in the field of technology, startups and innovation. we invited people like alessandro risaro co-founder of DataPizza, that is trying to create a connection between the italian tech industry and workers.</p> <p>After around a year of recording and 10 episodes published we decided to merge with another podcast, that can still be found on Spotify. OVERHEAR is a podcast that has been going on and off for a couple of years and was originally held by Tommaso Lucarelli, Stefano Frosi and Emanuele Baldelli. </p> <p>We came around for the fourth season of the podcast and we recorded a series of episodes with them, inviting professors of  Universit\u00e0 degli studi di Milano (Paolo Boldi, Sebastiano Vigna, Christian Quadri) among others.</p> <p>Due to everyone in the group having different goals and different schedules unfortunately we had to stop the production of the podcast, but it was an amazing experience and an opportunity to do something great alongside very talented people.</p> Blog <p>Otakustuffreviews was a blog that I started in 2017 and it was just a fun project to write about the things I liked. I was always a fan of anime and manga and I wanted to share my thoughts on the things I watched.</p> <p>I kept on writing on the blog on and off for three years until I stopped in 2020.</p>"},{"location":"me/unimi/","title":"Unimi","text":"<p>I began my master in Computer Science at Universit\u00e0 degli studi di Milano (Unimi) in September 2022 wanting to focus on web development, distributed systems and cloud comptuing.</p> <p>After some time I discovered the existence of other fields, like machine learning, and I fell in love with the idea of using computer science as an instrument to support research in other fields. I started my thesis in September 2024 and it's titled \"Supervised machine learning techniques for quench detection in superconductors\" followed by professor Dario Malchiodi and Lucio Rossi.</p> <p>My university curriculum is a mix of theoretical computer science, with the following courses:</p> <ul> <li> <p>Algoritmi e complessit\u00e0 (Algorithms and Complexity) - A course about advanced algorithms.</p> </li> <li> <p>Metodi probabilistici per l'informatica (Probabilistic methods for computer science) - A course about Markov Chains and their applications in the field of computer science.</p> </li> <li> <p>Algoritmica per il web (web algorithmics) - A course about the latest technologies in the field of web algorithmics.</p> </li> <li> <p>Heuristic Algorithms - A course about heuristic and metaheuristic algorithms.</p> </li> </ul> <p>distributed systems, with the following courses:</p> <ul> <li> <p>Distributed and pervasive systems</p> </li> <li> <p>GPU computing</p> </li> <li> <p>Cloud computing Technologies</p> </li> </ul> <p>and some other misc courses like:</p> <ul> <li> <p>Calcolo numerico (Numerical Analysis) - A course about numerical methods for solving various problems.</p> </li> <li> <p>Reti wireless and mobili (Mobile and wireless networks)</p> </li> <li> <p>Fisica degli acceleratori 1 (Accelerator physics 1)</p> </li> <li> <p>Artificial intelligence - An introductory course about AI.</p> </li> <li> <p>Videogame design and programming</p> </li> </ul>"},{"location":"me/unimib/","title":"Unimib","text":"<p>I finished my bachelor with a degree in computer science at Universit\u00e0 degli studi di Milano Bicocca (Unimib) in 2022. I graduated with 102/110 with a thesis about the project that I did with a colleague for Certimeter group, a Torino based company. During the studies I went through the following exams:</p> <ul> <li> <p>Foundamentals of algebra</p> </li> <li> <p>Programming 1 and 2 - Java programming</p> </li> <li> <p>C++ programming</p> </li> <li> <p>Algorithms 1 and 2 - Basic algorithms and basic graph algorithms</p> </li> <li> <p>Programming languages - a course about programming in languages employing different paradigms (Common lisp and Prolog)</p> </li> <li> <p>Distributed systems</p> </li> <li> <p>Operations research</p> </li> <li> <p>Computer security</p> </li> <li> <p>Probability and statistics</p> </li> <li> <p>Databases</p> </li> <li> <p>Software engineering</p> </li> </ul>"},{"location":"pl/readme/","title":"Programming languages project","text":"<p>The project can be found on Github (MST implementation)</p> <p>This project was written mainly in Common Lisp and Prolog using emacs.</p> Introduction <p>The project was assigned for the course of Programming Languages at Universit\u00e0 degli studi Milano Bicocca held by professor Marco Antoniotti.</p> <p>The project consisted of the implementation of Prim's solution for the Minimum Spanning Tree problem using Common Lisp and Prolog. In the following I will provide the documentations of the two implementations written in italian.</p> Prolog documentation <p>NOTE AL LETTORE</p> <p>Il readme \u00e8 stato composto su Emacs rispettando la regola che impone di scrivere il testo entro le 80 colonne. Nel caso in cui all'interno del readme dovessero comparire caratteri illeggibili \u00e8 dovuto al fatto che \u00e8 stato fatto un porting da blocco note e nel testo originale erano presenti delle lettere accentate, dovrebbero essere state rimosse tutte in questa versione.</p> INTERFACCIA PROLOG PER LA MANIPOLAZIONE DEI DATI <p>NOTE AL LETTORE</p> <ul> <li> <p>Nell'ultima versione del file la prima regola consente di eliminare tutti i   dati presenti nella base di conoscenza con il predicato 'consult'</p> </li> <li> <p>All'interno dell'algoritmo abbiamo utilizzato una rappresentazione   \"ad arco doppio\" quindi all'interno della base di conoscenza avremo   l'arco di andata e l'arco di ritorno</p> </li> </ul> Predicati obbligatori <p>new_graph(G)</p> <p>Predicato che aggiunge un nuovo grafo di nome G alla base di conoscenza</p> <p>delete_graph(G)</p> <p>Predicato che rimuove il grafo di nome G e tutti i vertici e gli archi a lui associati dalla base di conoscenza, se su di esso e' stato eseguito l'algoritmo di Prim verranno cancellati anche i relativi vertex_key e vertex_previous</p> <p>new_vertex(G, V)</p> <p>Predicato che aggiunge un vertice V al grafo G, il predicato che rappresenta il vertice deve essere vertex(G, V)</p> <p>graph_vertices(G, Vs)</p> <p>Predicato che ritorna true se Vs e' una lista contenente tutti i vertici di G</p> <p>list_vertices(G)</p> <p>Predicato che stampa a console la lista dei vertici di G</p> <p>new_arc(G, U, V, Weight)</p> <p>Predicato che aggiunge un arco appartenente al grafo G alla base di conoscenza con le seguenti discriminanti:</p> <ul> <li>Se il grafo non esiste lo crea</li> <li>Se uno dei due vertici non esiste lo crea</li> <li>Se l'arco esiste gi\u00e0 lo sostituisce all'interno della base di conoscenza</li> </ul> <p>graph_arcs(G, Es)</p> <p>Predicato utilizzato per creare una lista Es contenente tutti gli archi del grafo G</p> <p>vertex_neighbors(G, V, Ns)</p> <p>Predicato che ritorna true se V e' un vertice del grafo G e Ns e' una lista contenente gli archi, arc(G, V, N, W), che portano ai vertici N immediatamente raggiungibili da V</p> <p>adjs(G, V, Vs)</p> <p>Predicato che ritorna true se V e' un vertice del grafo G e' Vs e' una lista che contiene i vertici, vertex(G, V), ad esso adiacenti</p> <p>list_arcs(G)</p> <p>Predicato che stampa a console la lista degli archi del grafo G</p> <p>list_graph(G)</p> <p>Predicato che stampa a console la lista dei vertici e degli archi del grafo G</p> <p>read_graph(G, FileName) Predicato che riceve un grafo dal file csv 'FileName' e lo inserisce nella base di conoscenza.</p> <p>Se il grafo esiste gia' lo sovrascrive</p> <p>write_graph(G, FileName)</p> <p>Predicato che riceve il nome di un file csv 'FileName' e ci scrive dentro il grafo G.</p> <p>write_graph(G, FileName, Type)</p> <p>Predicato che riceve il nome di un file csv 'FileName' e ci scrive dentro il grafo G secondo il valore dell'argomento Type. Type puo' essere graph o edges:</p> <ul> <li>Se Type e' graph allora G sar\u00e0 il nome di un grafo nella base di   conoscenza e il suo contenuto verra' scritto all'interno del file</li> <li>Se Type e' edges allora G e' una lista di archi e il suo contenuto   verra' scritto all'interno del file.</li> </ul> Predicati d'appoggio <p>arcConv([], [])</p> <p>Predicato che si occupa di fare una compressione di una lista di elementi arc/4 in una lista di elementi di arc/3 in modo da prepararla per essere inserita nel file .csv</p> <p>new_arcList([arc(X, Y, W) | T], G)</p> <p>Predicato che presa in ingresso una lista contenente tutti i termini arc/3 provenienti dal file .csv passa gli argomeni di arc/3 a new_arc/4 che li inserisce nella base di conoscenza aggiungendo l'informazione del grafo</p> GESTIONE DELLO HEAP Predicati obbligatori <p>new_heap(H)</p> <p>Predicato che inserisce un nuovo heap nella base di conoscenza, la prima posizione all'interno dello heap e' 0</p> <p>delete_heap(H)</p> <p>Predicato che elimina uno heap dalla base di conoscenza e tutte le heap_entry ad essa legate</p> <p>heap_has_size(H, S)</p> <p>Predicato che restituisce true quando S e' la dimensione attuale dello heap</p> <p>heap_empty(H)</p> <p>Predicato che restituisce true se l'heap H e' vuoto</p> <p>heap_not_empty(H)</p> <p>Predicato che restituisce true se l'heap H non e' vuoto</p> <p>heap_head(H, K, V)</p> <p>Predicato che restituisce true quando l'elemento dello heap H con chiave minima K e' V.</p> <p>heap_insert(H, K, V)</p> <p>Predicato che restituisce true quando l'elemento V viene correttamente inserito nello heap H con chiave K</p> <p>heap_extract(H, K, V)</p> <p>Predicato che restituisce true quando l'elemento V viene correttamente rimosso dall'heap H con chiave K</p> <p>list_heap(H)</p> <p>Predicato che stampa a console lo stato interno dello heap</p> Predicati d'appoggio <p>swap(H, SP, FP)</p> <p>Predicato che scambia due elementi SP-FP nello heap H</p> <p>heap_update(H, A)</p> <p>Predicato che incrementa/decrementa di A la dimensione dello heap H</p> <p>heap_switch(H, P)</p> <p>Predicato che si occupa di far scalare il figlio all'interno dello heap finche' il padre non e' minore o non diventa la radice.</p> <p>heapify(H, P)</p> <p>Predicato che riordina lo heap H rispettando 'heap property'</p> ALGORTIMO DI PRIM <p>NOTA AL LETTORE</p> <ul> <li> <p>Abbiamo deciso di implementare l'algoritmo di Prim impiegando gli   archi anzich\u00e8 i soli vertici come valori della heap_entry per un   semplice fatto di dispersivita'.   Penso che in questo modo tutte le informazioni siano sempre dove   devono essere e sono veloci da raggiungere in ogni momento   dell'esecuzione dell'algoritmo.</p> </li> <li> <p>Abbiamo deciso di eseguire la sort tramite la funzione consigliata da   Professor M. Antoniotti (la sort/4) che sfrutta il predicato di   riordino @=&lt;</p> </li> </ul> Predicati obbligatori <p>vertex_key(G, V, K)</p> <p>Predicato che restituisce true quando V e' un vertice di G e, durante e dopo l'esecuzione dell'algoritmo di Prim, contiene il peso minimo di un arco che connette V nell'albero minimo; se questo arco non esiste (ed all'inizio dell'esecuzione) allora K e' inf</p> <p>vertex_previous(G, V, U)</p> <p>Predicato che restituisce true quando V ed U sono vertici di G e il vertice U e' il vertice 'genitore' di V nel minimum spanning tree</p> <p>mst_prim(G, Source)</p> <p>Questo predicato ha successo con un effetto collaterale. Dopo la sua esecuzione, la base-dati Prolog ha al suo interno i predicati vertex_key(G, V, K) e vertex_previous(G, V, U) per ogni V appartenente a G</p> <p>mst_get(G, Source, PreorderTree)</p> <p>Questo predicato e' vero quando PreorderTree e' una lista degli archi dell' Mst ordinata secondo un attraversamento preorder dello stesso fatta rispetto al peso dell'arco, nel caso di vertici di peso uguale si \u00e8 opera un ordinamento lessicografico degli stessi (vedi nota sopra).</p> Predicati d'appoggio <p>mst_algorithm(G, Source, H)</p> <p>Predicato che si occupa della parte computazionale dell'algoritmo di prim visitando il grafo in profondita', la computazione ha fine quando la heap che contiene gli archi rimane vuota</p> <p>clean_previous_mst(G)</p> <p>Predicato che cancella tutti i dati di una precedente esecuzione dell'algoritmo di prim sul grafo G dalla base di conoscenza</p> <p>mst_neighbours(G, V, Arcs)</p> <p>Predicato che crea una lista di archi percorribili dal nodo V ai vicini di V del grafo G</p> <p>mst_prim_initialization(G, H)</p> <p>Predicato che costruisce una lista di archi fittizi del tipo arc(G, vertice, X, inf) utili solamente all'inizializzazione dell'algoritmo e chiama heap_insertion_list e vertex_key_initialization</p> <p>vertex_key_initialization(G, [arc(G, vertice, X, inf) | T])</p> <p>Il predicato prende in ingresso la lista di archi generati dalla mst_prim_initialization e va a creare una entry vertex_key per ciascuno di essi mettendo la loro distanza ad infinito. I vertex previous non vengono inizializzati prima dell'inizio della computazione</p> <p>heap_insertion_list([arc(G, U, V, Weight) | T], H)</p> <p>Predicato che inserisce una lista di arc/4 nello heap, secondo le seguenti regole:</p> <ul> <li>L'arco viene inserito se e solo se il nodo di destinazione non e' ancora   stato visitato</li> <li>Se all'interno dello heap vi e' un arco con la medesima destinazione ma peso   maggiore, verra' sostituito dall'arco in ingresso e verranno   aggiornate le relative vertex_key e vertex_previous</li> <li>Nel caso il nodo sia stato gia' visitato o vi e' un arco con peso inferiore   diretto allo stesso nodo all'interno dello heap, verra' scartato</li> </ul> <p>change_previous(G, Dest, Father, New_Father)</p> <p>Il predicato si occupa di cancellare la vecchia entry vertex_previous sostituendola con quella nuova che \u00e8 stata trovata durante l'aggiornamento della heap tramite la visita dei vicini.</p> <p>mst_calculation([arc(G, U, V, Weight) | T], Mst)</p> <p>Predicato che si occupa di visitare l'albero in preorder inserendolo in una lista che verra' restituita come Mst</p> <p>list_sort(List, Sorted)</p> <p>Predicato che ordina List rispetto al peso dell'arco. In caso di archi con pari peso ordina rispetto all'ordinamento 'lessicografico' del vertice destinazione.</p> <p>regularize([arc(G, U, V)], [arc(G, U, V, Weight)])</p> <p>Predicato che trasfroma arc/3 in arc/4 aggiugendone il peso associato</p> Common Lisp documentation <p>NOTE AL LETTORE</p> <ul> <li> <p>Come per il Readme di Prolog, anche questo testo rispetta la   convenzione delle 80 colonne e, allo stesso modo, e' stato   originariamente importato da un file di testo formattato tramite   blocco note, questo significa che qualunque carattere illeggibile   dovesse apparire all'interno del testo e' una lettera accentata non   riconosciuta; questa versione del file dovrebbe essere priva di   refusi di questo tipo.</p> </li> <li> <p>Ogniqualvolta vi dovesse essere un riferimento al linguaggio Lisp   all'interno del file si trattera' di un'abbreviazione del nome   Common Lisp e non di un riferimento erroneo all'intera famiglia di   linguaggi</p> </li> </ul> <p>INTERFACCIA LISP PER LA MANIPOLAZIONE DEI DATI</p> Funzioni obbligatorie <p>new-graph (graph-id -&gt; graph-id)</p> <p>Funzione che genera un nuovo grafo e lo inserisce nella hash-table _graphs_</p> <p>is-graph (graph-id -&gt; boolean)</p> <p>Funzione che ritorna il graph-id se il grafo esiste, altrimenti ritorna NIL</p> <p>delete-graph (graph-id -&gt; NIL)</p> <p>Funzione che rimuove il grafo graph-id dal sistema (con vertici archi etc)</p> <p>new-vertex (graph-id vertex-id -&gt; vertex-rep)</p> <p>Funzione che aggiunge un nuovo vertice vertex-id al grafo graph-id</p> <p>graph-vertices (graph-id -&gt; vertex-rep-list)</p> <p>Funzione che ritorna una lista di vertici del grafo</p> <p>new-arc (graph-id dep-id arr-id &amp;optional (weight 1) -&gt; arc-rep)</p> <p>Funzione che aggiunge un arco del grafo graph-id nella hash-table _arcs_ Se il grafo o uno dei due vertici non esistono viene restituito un errore.</p> <p>Si e' deciso, per comodita', di utilizzare una rappresentazione che inserisca nella hashtable l'arco di andata e l'arco di ritorno, inoltre qualora fosse gia' presente all'interno della hashtable un arco che ha la stessa destinazione questo verra' sovrascritto al nuovo valore.</p> <p>Per concludere, in questa funzione si fa uso per la prima volta della hashtable _neighbors_ che contiene tutti gli archi vicini di ogni vertice, quando creiamo un nuovo grafo, questo verr\u00e0 inserito all'interno della tavola (la sua utilita' viene spiegata nella sezione delle strutture dati aggiuntive).</p> <p>graph-arcs (graph-id -&gt; arc-rep-list)</p> <p>Funzione che ritorna una lista di tutti gli archi presenti nel grafo graph-id</p> <p>graph-vertex-neighbors (graph-id vertex-id -&gt; arc-rep-list)</p> <p>Funzione che ritorna una lista arc-rep-list contenente gli archi che portano ai vertici N immediatamente raggiungibili dal vertice vertex-id</p> <p>graph-vertex-adjacent (graph-id vertex-id -&gt; vertex-rep-list)</p> <p>Funzione che ritorna una lista vertex-rep-list contenente i vertici adiacenti al vertice vertex-id</p> <p>graph-print (graph-id)</p> <p>Funzione che stampa a console la lista dei vertici e degli archi del grafo graph-id</p> Strutture d'appoggio <p>hashtable _neighbours_</p> <p>Fa corrispondere ad ogni vertice una lista dei suoi archi vicini. Ho deciso di crearla, andando ad occupare pi\u00f9 spazio, perch\u00e8 migliora drasticamente le performance del nostro algoritmo. Siamo passati da 90 secondi di tempo di esecuzione sul file \"primkiller_50k.LISP\" gentilmente concessoci dal nostro collega Luca di Pierro a meno di un secondo sullo stesso input cambiando solamente il modo in cui si accede ai vicini di ciascun nodo.</p> <p>hashtable _positions_</p> <p>Fa corrispondere ad ogni oggetto dello heap la sua posizione all'interno dell'array che che memorizza lo heap. Implementata in modo da avere un tempo di accesso ai dati all'interno dello heap costante e non dover implementare una ricerca lineare che sarebbe lunga e costosa</p> <p>hashtable _visited_</p> <p>Fa corrispondere ad ogni vertice del grafo un booleano che indica se un nodo e' o non e' gia stato visitato in precedenza</p> Funzioni d'appoggio <p>is-vertex (graph-id vertex-id -&gt; vertex-rep o NIL)</p> <p>Funzione che ritorna il vertex-id se il vertice esiste, altrimenti ritorna NIL</p> <p>find-arc (graph-id dep-id arr-id neighbors -&gt; arc-rep o NIL)</p> <p>Funzione che cerca all'interno di una lista l'arco che vada da dep-id ad arr-id, l'abbiamo implementata perch\u00e8 quando andiamo a modificare un arco che gi\u00e0 esiste nella hashtable vogliamo che questa modifica si ripercuota anche sulla hashtable _neighbors_.</p> <p>is-arc (graph-id dep-id arr-id -&gt; arc-rep o NIL) Funzione che ritorna l'arco con vertice di partenza dep-id e vertice di arrivo arr-id se esiste, altrimenti ritorna NIL</p> GESTIONE DELLO HEAP Funzioni obbligatorie <p>new-heap (heap-id &amp;optional (capacity42) -&gt; heap-rep)</p> <p>Funzione che inserisce un nuovo heap nella hash-table _heaps_. La numerazione delle posizioni interne allo heap parte da 0</p> <p>heap-size (heap-rep -&gt; heap-size)</p> <p>Funzione che restituisce la dimensione attuale dello heap</p> <p>heap-id (heap-rep -&gt; heap-id)</p> <p>Funzione che restituisce l'id dello heap</p> <p>heap-actual-heap (heap-rep -&gt; actual-heap)</p> <p>Funzione che restituisce l'array che contiene i dati dello heap</p> <p>heap-delete (heap-id -&gt; T)</p> <p>Funzione che elimina uno heap identificato da heap-id dalla hashtable</p> <p>heap-empty (heap-id -&gt; boolean)</p> <p>Funzione che restituisce true se l'heap heap-id e' vuoto</p> <p>heap-not-empty (heap-id -&gt; boolean)</p> <p>Funzione che restituisce true se l'heap heap-id non e' vuoto</p> <p>heap-head (heap-id -&gt; (K V))</p> <p>Funzione ritorna una lista di due elementi dove K \u00e8 la chiave minima e V il valore associato</p> <p>heap-insert (heap-id key value -&gt; boolean)</p> <p>Funzione che restituisce true quando l\u2019elemento V viene correttamente inserito nello heap heap-id con chiave K e la sua posizione viene salvata nell'hashtable _positions_.</p> <p>Chiama una funzione heap_switch per fare in modo che il valore inserito galleggi verso l'alto andando a piazzarsi nella posizione corretta.</p> <p>Se la dimensione dello heap raggiunge la dimensione dell'array aumenta la dimesione dell'array di 10</p> <p>heap-extract (heap-id -&gt; (K V))</p> <p>Funzione che restituisce una lista con K, V e con K minima, la coppia viene rimossa dallo heap heap-id e dall'hashtable _positions_.</p> <p>Se la dimensione dello heap e' diversa da quella dell'array elimina le celle dell'array in eccesso</p> <p>heap-print (heap-id -&gt; boolean)</p> <p>Funzione che stampa a console lo stato interno dello heap heap/id</p> Funzioni d'appoggio <p>is-heap (heap-id -&gt; boolean)</p> <p>Funzione che restituisce true se l'heap esiste, altrimenti restituisce false</p> <p>heap-update (heap-id amount -&gt; heap-rep)</p> <p>Funzione che cambia la dimensione dello heap di amount</p> <p>get-father (heap-id pos -&gt; (K V))</p> <p>Funzione che restituisce la coppia (K V) che occupa la posizione del padre</p> <p>get-element (heap-id pos -&gt; (K V))</p> <p>Funzione che restituisce la coppia (K V) che occupa la posizione indicata</p> <p>set-element (heap-id key value pos -&gt; pos)</p> <p>Funzione che imposta l'oggetto in posizione pos alla coppia (key value) Viene aggiornato anche il valore nella hashtable _positions_</p> <p>swap-pos (heap-id key value pos -&gt; pos) Funzione che si occupa dello spostamento dell'elemento della coppia (key value) nella posizione del padre e dello spostamento inverso, cambiando di conseguenza la hashtable _positions_</p> <p>swap (heap-id key value pos1 pos2 -&gt; pos)</p> <p>Funzione che scambia le due coppie (key value) delle posizioni pos1 e pos2, cambiando di conseguenza le posizioni all'interno della hashtable _positions_</p> <p>delete-node (heap-id pos -&gt; T)</p> <p>Funzione che cancella il nodo in posizione pos dallo heap heap-id</p> <p>get-position (heap-id key -&gt; pos o NIL) Funzione che restituisce la posizione di un elemento all'interno dell'array che contiene i dati dello heap.</p> <p>Sebbene il nome possa essere fuorviante, abbiamo utilizzato il valore V di ogni coppia (K V) come chaive all'interno della hashtable _positions_, qualcosa di pi\u00f9 riguardo a questa implementazione nella prossima sezione</p> <p>fp (pos -&gt; pos)</p> <p>Funzione che restituisce la posizione del padre</p> <p>left-son (pos -&gt; pos)</p> <p>Funzione che restituisce la posizione del figlio sinistro</p> <p>right-son (heap-id -&gt; pos)</p> <p>Funzione che restituisce la posizione del figlio destro</p> <p>heap-switch (heap-id key value pos -&gt; T)</p> <p>Funzione che si occupa di far risalire verso l'alto la coppia (key value) fino a che l'elemento non diventa maggiore del padre o non diventa l'elemento in posizione 0 all'interno dello heap</p> <p>heapify (heap-id key value pos -&gt; T)</p> <p>Funzione che si occupa di far rispettare allo heap heap-id la heap property</p> <p>positions-print (heap-id -&gt; NIL)</p> <p>Funzione che stampa le posizioni delle chiavi presenti all'interno dello heap heap-id, inoltre le celle vuote non vengono considerate</p> ALGORTIMO DI PRIM <p>NOTE AL LETTORE</p> <ul> <li>Come detto prima abbiamo impiegato il valore V della coppia (K V)   per ogni elemento presente all'interno dello heap per indicizzare i   valori nella hashtable _positions_, questa scelta ci ha costretti a   virare dall'originale implementazione in prolog che consisteva   nell'inserire gli archi all'interno della heap direttamente, mentre   in prolog potrebbe non dare un vantaggio rilevante, in lisp il fatto   di avere direttamente a portata di mano il genitore di ogni nodo   all'interno dello heap puo' essere utile ed evitarci di andare a   visitare i vicini troppe volte.</li> </ul> <p>Il motivo per cui non mi sono sentito di creare un'implementazione   del genere e' per il fatto che all'interno dello heap le entry   sarebbero state del tipo</p> <p>(list 'arc 'graph 'dep 'arr 'weight)</p> <p>e, a meno che non si riduce il numero di elementi inseriti nella   hashtable positions ai soli 'graph e 'arr accedere alla hashtable   positions diviene poi impossibile, questo perch\u00e8: come faccio a   trovare la posizione di un arco come quello indicato sopra se non so   quale sia il nodo di partenza originale e il peso che avevo prima?</p> <ul> <li>Per la mst-get, su indicazione del professor M. Antoniotti, ci siamo   comportati come in Prolog, impiegando la funzione sort che ci   consente di implementare una nostra versione della funzione di   ordinamento, nel caso di confronti tra numeri abbiamo impiegato il   confronto aritmetico puro, nel resto dei casi abbiamo impiegato la funzione   string&lt; per decretare l'ordine</li> </ul> Funzioni obbligatorie <p>mst-vertex-key (graph-id vertex-id -&gt; K)</p> <p>Funzione che dato un vertex-id di un grafo graph-id ritorna il peso minimo di un arco che connette vertex-id nell\u2019albero minimo; se questo arco non esiste allora k \u00e8 MOST-POSITIVE-DOUBLE-FLOAT</p> <p>mst-previous (graph-id V -&gt; U)</p> <p>Ritorna il vertice U che e' il vertice genitore di V nel mst</p> <p>mst-prim (graph-id source -&gt; NIL)</p> <p>Funzione che termina con un effetto collaterale. Dopo la sua esecuzione, la hash-table vertex-keys contiene al suo interno le associazioni (graph-id V) \u21d2 K per ogni V appartenente a graph-id; la hash-table previous contiene le associazioni (graph-id V) \u21d2 U calcolate durante l\u2019esecuzione dell\u2019algoritmo di Prim.</p> <p>La funzione inizializza la dimensione dell'array dello heap, che conterra' i vertici del grafo, al numero totale di vertici presenti nel grafo in ingresso</p> <p>mst-get (graph source -&gt; preorder-mst)</p> <p>Funzione che ritorna preorder-mst che \u00e8 una lista degli archi del MST ordinata secondo un attraversamento preorder dello stesso, fatta rispetto al peso dell\u2019arco.</p> <p>Nel caso di archi con peso uguale si e' deciso di stamparli secondo l'ordine lessicografico</p> Funzioni d'appoggio <p>mst-algorithm (graph-id source heap -&gt; NIL)</p> <p>Funzione che si occupa della gran parte della computazione dell'algoritmo di prim, durante la sua esecuzione modifica i vertex key e mst previous dei vertici che compaiono nello heap, e' in grado di gestire componenti non connesse riconoscendole per la loro distanza infinita(most positive double float) dalla componente in analisi.</p> <p>La computazione ha fine quando la heap diventa vuota</p> <p>clean-previous-mst (graph-id -&gt; T)</p> <p>Funzione che elimina tutte le entry nelle hashtable _vertex-keys_ e _previous_ del grafo graph-id</p> <p>mst-prim-initialization (graph source heap -&gt; NIL)</p> <p>Funzione che inizializza le strutture dati ausiliarie neccessarie al corretto funzionamento dell'algoritmo di prim:</p> <ul> <li>inizializza i vertex-key a infinito</li> <li>i nodi a non visitato</li> <li>inizializza a infinito la distanza dei nodi all'interno dello heap</li> </ul> <p>set-not-visited (graph-id vertex-id -&gt; NIL)</p> <p>Imposta a NIL il valore del vertice vertex-id all'interno dell'hashtable visited</p> <p>set-visited (graph-id vertex-id -&gt; T)</p> <p>Imposta a T il valore del vertice vertex-id all'interno dell'hashtable _visited_</p> <p>heap-insertion-list (heap-id arc-list -&gt; T)</p> <p>Funzione che inserisce gli archi all'interno di arclist nello heap heap-id secondo il seguente criterio:</p> <ul> <li>L'arco viene inserito all'interno dello heap se e solo se la destinazione non   e' ancora stata visitata</li> <li>se il peso dell'arco e' minore del peso memorizzato all'interno   dello heap il valore viene sovrascritto e vengono cambiati i   vertex-key e vertex-previous corrispondenti</li> <li>altrimenti si prosegue con l'inserimento.   L'esecuzione termina quando la lista e' vuota</li> </ul> <p>set-key (heap-id weight pos -&gt; (K V))</p> <p>Funzione che cambia la chiave di una coppia (K V) all'interno dello heap in posizione pos</p> <p>already-visited (graph vertex -&gt; boolean)</p> <p>Funzione che restituisce true se il nodo e' gia' stato visitato, false altrimenti</p> <p>set-vertex-key (graph-id heap-entry -&gt; K)</p> <p>Funzione che setta vertex-key di un nodo a un certo valore</p> <p>set-mst-previous (graph-id heap-entry -&gt; U)</p> <p>Funzione che chiama find-father sulla lista dei vicini del nodo in modo da cercare il padre del vertice contenuto in heap-entry cos\u00ec da settarne il valore del padre a U</p> <p>find-father (graph heap-entry arc-list -&gt; arr-id)</p> <p>Funzione che restituisce l'id del vertice di arrivo di un arco che parte dal nodo che stiamo considerando e arriva in arr-id.</p> <p>Nota: Restituiamo arr-id perche' i nodi presenti in arc-list sono i vicini del nodo che stiamo ispezionando ma il grafo che a noi interessa corre in direzione opposta</p> <p>get-graph (arc -&gt; graph-id)</p> <p>Funzione che restituisce il grafo a cui appartiene un arco arc</p> <p>get-departure(arc -&gt; dep-id)</p> <p>Funzione che restituisce il vertice di partenza di un arco arc</p> <p>get-arrival(arc -&gt; arr-id)</p> <p>Funzione che restituisce il vertice di arrivo di un arco arc</p> <p>get-weight (arc -&gt; weight)</p> <p>Funzione che restituisce il peso dell'arco arc</p> <p>mst-calculation (graph-id arc-list -&gt; arc-list)</p> <p>Funzione che fa la maggior parte del lavoro di computazione per la mst-get, si occupa della costruzione dell'albero in preorder tree appoggiandosi alla funzione list-sort</p> <p>list-sort (arc-list -&gt; arc-list)</p> <p>Funzione che mette in ordine una lista secondo l'ordinamento dei pesi. Se due oggetti hanno lo stesso peso, utilizza l'ordinamento lessicografico per le stringhe e l'ordinamento aritmetico per i numeri</p> <p>regularize (arc-list -&gt; arc-list)</p> <p>Funzione che prende in ingresso una lista di archi arc/3, simile a quanto accadeva in prolog, e restituisce la lista ricostituita in cui ogni arco ha il rispettivo peso</p> <p>find-mst-previous (graph source -&gt; arc-list) Funzione che restituisce una lista contenente i previous di un nodo inserendoli all'interno di una lista, serve per costruire gli arc/3 di cui ho parlato nella precedente funzione</p>"},{"location":"structures/readme/","title":"Discrete structures 1","text":"<p>The project can be found on GitHub (Discrete Structures 1 project)</p> <p>This project was written mainly in LaTeX.</p>  Introduction  <p>The idea behind this project was to provide students with an open source version of the notes for the course of Discrete Structures 1 held by professor Bertille Granet and professor Felix Joos at University Karl Ruprecht of Heidelberg, the notes are in english and have not been updated since the beginning of this year.</p> <p>These notes are currently undergoing some maintenance, therefore the last pdf version is not in the best shape, a future release is bound to fix its appearance. The latest version of the notes can be downloaded at the link below.</p> <p>Download DS1 notes</p>"},{"location":"vdp/readme/","title":"Pump down the flame","text":"<p>The original project page with the download links can be found here Polimi Game Collective.</p> <p>This project was mainly written in C# using Unity.</p> Introduction <p>Pump down the flame was a project I developed alongside Federico Maglione, Fabio Patella and Nicol\u00f2 Fasulo to participate in the 2022 Videogame Design and Development course. The game was a 2d level-based platformer in which the objective was to save a series of hostages from terrorists before the time ran out and without dying.</p> <p>The game was developed using Unity and the sprites were a mix of free asstes and assets created using midjourney and stable diffusion. The game was developed in a span of circa 3 months and was one of the most appreciated games of the course gaining us an overall 6th place out of 24 games and a final grade of 27/30.</p>"}]}