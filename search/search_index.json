{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome on my portfolio website!</p> <p>I'm a computer science student at the end of my master studies at University of Milan, I have been interested in past years in the field of distributed systems technologies and cloud environments, I am now moving towards the field of applied machine learning after the course of Machine Learning for Physics held by professor Tilman Plehn at Karl Ruprecht university of Heidelberg.</p> <p>I am in the process of starting my master Thesis titled \"Supervised machine learning techniques for quench detecction in superconductors\" accompanied by both professors Dario Malchiodi and Lucio Rossi.</p>"},{"location":"algoweb/readme/","title":"Algoweb","text":"<p>The project can be found on Github (Algoweb project)</p> Introduction <p>Review of the lecture notes for the course of Web algorithmics, held by professor Sebastiano Vigna at Universit\u00e0 degli studi di Milano, the lecture notes are in italian and are updated to the end of last year.</p> <p>They are still a very viable option for all the students that take the course.</p> <p>I consider this project alongside my other project for the course of Discrete Structures 1 to be a good showcase of my abilities with the LaTeX language. To see the latest revision of the notes just follow the link below.</p> <p>Download Algoweb 2.0</p>"},{"location":"autoencoders/readme/","title":"Anomaly detection","text":"<p>The project can be found on Github (Autoencoders project), consider that the code cannot be executed unless a different dataset is provided (the original dataset url was taken down).</p> Introduction <p>I did this project alongside Mario Massimo (his github) during my stay in Heidelberg for the course of Machine Learning and Physics held by professor Tilman Plehn, the project was aimed at comparing the performance of two different machine learning architectures, the first one being an MLP based autoencoder and the second one being a CNN based autoencoder.</p> <p>The dataset came from the professor and a given preprocessing step was applied to turn the tracker information coming from the LHC into 40x40 images.</p> <p>The task at hand was: given the dataset, containing two different types of jets (Quantum Chromo Dynamics and Top), use one of the two jets as signal and the other as anomaly. The following image is an averaging of over 5000 jets taken from FPGA-Accelerated Machine Learning Inference as a Service for Particle Physics Computing and it is clear to see that the area spanned by the top jets is way wider than the one spanned by the QCD jets. That is because of the three-pronged structure of the top jets, which is not present in the QCD jets. </p> Top (right) vs QCD (left) jets <p>When it comes to a more practical scenario, whenever top jets are signal and QCD jets are anomaly it's quite likely that the model will have a harder time finding the anomaly since in most cases QCD jets can be seen as a top jet whose prongs are extremely close together. This means in turn that the reconstruction performance of our model will be worse when the QCD jets are the anomaly.</p> <p>The code can be found on my github repository alongside some commentary, unfortunately the dataset is not available anymore, therefore there is no visible results but the code is still up for reading alongside some commentary. The requirements of the sheet can be downloaded below.</p> <p>Download sheet requirements</p>"},{"location":"bachelor/readme/","title":"Bachelor Thesis","text":"<p>The project can be found on Github (Bachelor project)</p>  Introduction  <p>My bachelor project consisted in the development of a microservice-based web application to securely handle sensitive user data for a company. The project was presented in July 2021.</p> <p>The project consisted of six components:</p> <ul> <li>Frontend - Developed using React.js</li> </ul> <p>The following components developed using Spring Boot:</p> <ul> <li> <p>Gateway - The entry point of the application</p> </li> <li> <p>Security microservice</p> </li> <li> <p>Backend microservice</p> </li> </ul> <p>And then two MySQL databases:</p> <ul> <li> <p>Security database - which handles only the basic user information (email, password, isEnabled)</p> </li> <li> <p>Primary database - which handles the rest of the user information</p> </li> </ul> <p>To handle the distribution of the microservices both Dockerfile and Docker-compose were used. The UI of the project is shown in the following figure.</p> Home of the user view  Functionalities  <p>The application allows the generic user to:</p> <ul> <li> <p>Register</p> </li> <li> <p>Login</p> </li> <li> <p>Update their information (both personal and linked to hard and soft skills that they might have)</p> </li> </ul> <p>The top level user is able to:</p> <ul> <li> <p>Cancel users</p> </li> <li> <p>Search any user inside the database and view or modify their information</p> </li> <li> <p>Disable users</p> </li> </ul> <p>The docker-compose.yaml file was written as follows, since the application was only for demo pourposes the database passwords were as easy as possible and no information was encrypted.</p> <pre><code>version: \"3.9\"\n\nservices:\n  userdb:\n    container_name: user_database\n    image: mysql\n    restart: always\n    environment:\n      - MYSQL_ROOT_PASSWORD=password\n      - MYSQL_DATABASE=database-utenti\n    ports:\n      - \"3307:3306\"\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p password\"]\n      timeout: 20s\n      retries: 15\n\n  securitydb:\n    container_name: security_database\n    image: mysql\n    restart: always\n    environment:\n      - MYSQL_ROOT_PASSWORD=password\n      - MYSQL_DATABASE=database-sicurezza\n    ports:\n      - \"3308:3306\"\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p password\"]\n      timeout: 15s\n      retries: 15\n\n  blue-whale:\n    container_name: gatewayB\n    build:\n      context: ./backend-gateway\n      dockerfile: \"Dockerfile\"\n    ports:\n      - \"8080:8080\"\n\n  sleepin-cat:\n    container_name: usersB\n    build:\n      context: ./backend-gestione-utenti\n      dockerfile: \"Dockerfile\"\n    depends_on:\n      userdb:\n        condition: service_healthy\n    ports:\n      - \"8082:8082\"\n\n  honeybear:\n    container_name: securityB\n    build:\n      context: ./backend-login\n      dockerfile: \"Dockerfile\"\n    depends_on:\n      securitydb:\n        condition: service_healthy\n    ports:\n      - \"8081:8081\"\n\n  frontend:\n    container_name: frontend\n    build:\n      context: ./frontend\n      dockerfile: \"Dockerfile\"\n    ports:\n      - \"3000:3000\"\n</code></pre> <p>The final thesis for the project can be found on Github as well as the presentation I put together for the final bachelor thesis discussion. The download links are the following:</p> <p>Download last version of the thesis</p> <p>Download last version of the presentation</p>"},{"location":"deployment_of_llms_in_6G_networks/readme/","title":"Deployment of LLMs at the edge of the 6G network","text":"<p>This project was a research paper written for the course of Cloud Computing Technologies held by Professors Claudio Ardagna and Marco Anisetti at Universit\u00e0 degli studi di Milano.</p> <p>The idea of the project came from me and was further expanded by me because I was captured by something I read a while back which the following question was asked: \"What if 5G was enough? Do we really need 6G?\".</p> <p>My research is meant to do some paper-reviewing as well as try to explain the areas of major interest in the field of distributed learning techniques (which I identify as the only solutions currently available to handle in a timely fashion models as big as LLMs).</p> <p>In the paper I go through the following steps:</p> <ul> <li> <p>Introduction.</p> </li> <li> <p>6G overview: using a whitepaper from Nokia, I go through the 6 key aspect of the new 6G communication standard putting more emphasis on the fact that 6G should be a network that is shaped to the user's need and liking and therefore it's going to make heavy use of AI approaches like LLMs.</p> </li> <li> <p>Opportunities: I use this section to briefly expose opportunities that have been identified in the literature and then I move to explaining my idea of the architecture, that builds upon the spectrum distribution showed in the previous section.</p> </li> <li> <p>Technical limitations: I use this section to expose some of the evident problems connected to the need of having LLMs stored in the network in locations that are as close as possible to the end users and I also propose some solutions found in literature in the field of distributed learning (Federated Learning, Split Learning and LoRA).</p> </li> </ul> <p>The pdf for both the paper and the presentation can be found at the links below</p> <p>Download the paper</p> <p>Download the presentation</p>"},{"location":"greenfield/readme/","title":"Greenfield","text":"Greenfield <p>The project can be found on Github (Greenfield project)</p> Introduction <p>In this repository is contained all of the code for the project of Distributed and Pervasive Systems by Professor Ardagna and Professor Bettini at Universit\u00e0 degli Studi di Milano, the project was presented in September 2023. In the README file is contained the analysis of the work I did as well as some informations regarding things that I would like to do in the future to make it better. Before beginning the explanation I would like to point out that throughout this file I will generally talk about robots and processes really freely, they are the same thing, threads are of course light-processes that are sons of the <code>Main</code> class that is associated to any Robot. In the project we were required to simulate a smart city's cleaning system, we had a set of processes roaming around and collecting pollution data that were autonomously sent to the server, each of the robots had a 10 percent probability of having problems and needing to go to a mechanic for repairs. The mechanic was able to handle one repair process at a time thus the project needed to handle different requests arriving at the mechanic in parallel. The full project description can be found in ./project_assignement.</p> Structure of the solution <p>The following is the list of all the classes that I chose to implement for this project</p> <ul> <li>Main</li> <li>Admin Client</li> <li>Admin Server<ul> <li>Server Rest Interface</li> <li>MQTT Subscriber</li> <li>Bot Positions</li> <li>Average List</li> </ul> </li> <li>Cleaning Bot<ul> <li>Bot Services</li> <li>Service Comparator</li> <li>Waiting Thread</li> <li>Bot Thread</li> <li>Eliminator Thread</li> <li>Fix Helper Thread</li> <li>GRPC Services Thread (GRPC server)</li> <li>Input Thread</li> <li>Maintenance Thread</li> <li>Measurement Gathering Thread</li> <li>Mutual Exclusion Thread</li> <li>Pollution Sensor Thread</li> <li>Quit Helper Thread</li> <li>Bot Identity Comparator</li> <li>Bot Utilities</li> <li>Comm Pair</li> <li>Measurement Buffer</li> <li>Position</li> </ul> </li> <li>Extra<ul> <li>Atomic Counter</li> <li>Atomic Flag</li> <li>Logger</li> <li>Thread Safe data structure wrapper</li> </ul> </li> <li>Simulator Code</li> <li>Variables</li> </ul> <p>My implementation is quite thread heavy, but I wanted to really experiment as much as possible with it, to get to know and understand how threads work and how to control them while accessing information together.</p> Operations <p>In the following I will discuss my implementation for the different operations.</p> Join <p>When a new process is created it starts the initiator thread, which is simply a thread that instanciates and starts all of the necessary services (e.g. the GRPC Services Thread). in the meanwhile it requests the server to join the network, the join operation currently consists of two parts:</p> <ul> <li>Addition of the new robot to the Admin Server's local structure</li> <li>Communication of personal data (i.e. an instance of the BotIdentity class) to all of the robots in the network</li> </ul> <p>The GRPC communication is asynchronous, and I decided to do two different HTTP requests (check ID availability, communicate my existence to the network) to highlight the difference between the two tasks. The position in the city is chosen by the Admin Server simply by checking in the system which one is the district with the lowest current density. Originally it was supposed to pick a random district uniformly, while the solution would tend to a stable distribution (if enough processes were initialized), it would not be stable for the majority of the low density cases.</p> Comm Pair <p>The <code>CommPair</code> class is a simple toy I came up with, it's nothing more than a pair containing a <code>ManagedChannel</code> and a <code>GRPCStub</code>. The idea behind it is simply to keep on recycling open stubs and channels; thus saving the resources necessary to open a new one each and every time a communication has to take place. Since the project is required to rely heavily on GRPC communication. Comm Pairs are clustered into <code>ThreadSafeHashMaps</code>, each of the pairs is associated to the hash of the <code>BotIdentity</code> the <code>ManagedChannel</code> connects to.</p> Maintenance process <p>The maintenance process i s handled by two different threads, one deals with checking whether the robot should go under maintenance or not, the other built and initialized when the robot undergoes maintenance and handles communication and the maintenance procedure. The maintenance process uses a new thread to carry out the function, something that I didn't mention above was that, to handle potential concurrent removals and insertions, any operation involving the network to its full extent would be done by taking a snapshot of the network. The GRPC is asynchronous and carried out in parallel, any removals necessary are postponed until the time for maintenance is up, thus the removal and stabilization (which do not come cheap) are done at most once per process.</p> Pollution measurements <p>Pollution measurements (more about this later) stop during maintenance, originally they would still be sent, but I decided against it becasue it would not make much sense.</p> Removal <p>The solution I implemented to handle removals is overengineered and overkill for the job and the setup of the project. The reason behind it is that it was originally thought to straighten even the worst distributions (e.g. 1-6, 2-0, 3-0, 4-0), keep in mind that I originally placed robots in the city randomly. The elimination works this way:</p> <ul> <li>I remove mentions of the dead robot from the local machine</li> <li>I contact the Admin Server to let him know that there are dead robots in the city</li> <li>Contact the other robots in the network to remove the references to dead robots from their systems</li> <li>Stabilize the data structure</li> </ul> <p>It's important to mention a couple of details</p> GRPC calls <p>For the elimination procedure, two different GRPC procedures have been called:</p> <ul> <li><code>moveRequest</code> -&gt; which is used by the robot dealing with the elimination process to tell another robot to move away from a district</li> <li><code>positionModificationRequest</code> -&gt; which is more like a notification, when a robot moves to another district computes a random position inside that district and lets every robot in the network know that its position is changed.</li> </ul> <p>Whenever a robot receives a <code>moveRequest</code> the thread waits until the position is changed and the robots in the network have been notified to perform the <code>onComplete</code> and <code>onNext</code> operations.</p> How robots are chosen <p>During the elimination procedure it's important to make sure that everyone is on the same page, to be sure about that I created a setup phase before stabilization where an auxiliary data structure is built. I decided to use a list of Priority Queues with a specific Comparator that allows me to do sorting on the robots by ID. The stabilization is later carried out just by moving around the top of the queues.</p> Pollution sensor <p>The pollution sensor is composed by four different entities:</p> <ul> <li>Simulator</li> <li>Measurement Buffer</li> <li>Measurement Gathering Thread</li> <li>Pollution Sensor Thread</li> </ul> <p>The Measurement Buffer implements a read/write cycle depending on the available size of the buffer. The cycle works unless the robot is on maintenance. The Measurement Gathering Thread keeps averages in memory until the Pollution Sensor Thread comes and takes them from him. This Thread, the same way the other did, stays on hold until the maintenance process is done. The Pollution Sensor Thread is the timer of the pipeline and handles MQTT broadcasting. Each MQTT broadcast will be at most 25 seconds apart from the one before, that is because I wanted to simulate the fact that the robot being broken down. To conclude the Admin Server will receive an MQTT message every: $15$ seconds + $min($ <code>REMAINING_MAINTENANCE_TIME</code> $, 10)$</p> FIX and QUIT commands <p>Both FIX and QUIT commands are being handled through dedicated threads, created once the commands are typed. To be fair the existence of a specialized thread just to send a process to the mechanic is really useless and could be avoided altogether. The QUIT command is a bit more complicated and having a thread in that case is a bit more useful, because if it has to wait doesn't lock the entirety of the input pipeline, but could still be removed in favour of a synchronized function.</p>"},{"location":"me/curriculum/","title":"Curriculum","text":"<p>Currently working on having a link down here to download the latest version of the curriculum vitae pdf file.</p> <p>In the meantime, this page acts as a web-based version of my curriculum vitae. It is updated regularly, so feel free to check back for the latest version.</p>  Contact Information  <p>You can always contact me using the following channels:</p> alexbgtt@gmail.com Linkedin  Education  <ul> <li> <p>Master student in Computer Science at the University of Milan (2022 - present)</p> </li> <li> <p>Erasmus student in Computer Science, Physics and Scientific Computing at Karl Ruprecht University of Heidelberg (Sep 2023 - Mar 2024)</p> </li> <li> <p>Bachelor's degree in Computer Science at the University of Milan Bicocca (2020 - 2022)</p> </li> <li> <p>Bachelor studente in Computer Engineering at Polythechnic of Milan (2018 - 2020)</p> </li> </ul>  Previous work experiences  <ul> <li> <p>Currently working as a tutor for international students at the University of Milan (2024 - present)</p> </li> <li> <p>Worked as a waiter for La Birrofila brewpub in Milan (May 2022 - Sep 2022)</p> </li> <li> <p>Did an internship as programmer for the bachelor thesis at the unimib (Feb 2021 - Jun 2021)</p> </li> <li> <p>Worked as a scrutineer for various elections in the city of Milan</p> </li> <li> <p>Worked as a private tutor for various students helping them facing exams and tests in various subjects (English, Mathematics, Electromagnetism, Physics, Computer Science, ...)</p> </li> </ul>  Projects  <p>For each project, I have provided a brief description as well as a link to the project's repository, and some downloadables. Everything can be found between the sections \"Old projects\" and \"Latest Project\".</p>  Laguages  <ul> <li>Italian: mother tongue</li> </ul> <p>The english level was certified many years ago through a First for english test and the result was B2. Since then I have done a series of other tests that are non certifying and provided very different results (between C1 and C2). I am confident that the current level is C1.</p> <ul> <li>English: C1</li> </ul> <p>Studied spanish many years ago but can still understand, read and speak about myself and some other topics. Some work would be required to reach a good level of proficiency.</p> <ul> <li>Spanish: A2</li> </ul> <p>Interests:</p> <ul> <li> <p>German</p> </li> <li> <p>French</p> </li> </ul>  Programming languages  <p>The following are the programming languages that I know and the ones that I feel the more comfortable with, I am going to use the same scale used to describe natural languages to trace a parallel. Clearly there is no certification for any of the languages below, apart from the projects that I did.</p> <ul> <li> <p>Java: C1</p> </li> <li> <p>Python: B2</p> </li> <li> <p>C: B1</p> </li> <li> <p>Cuda C: B1</p> </li> <li> <p>SQL: B1</p> </li> <li> <p>C++: A2</p> </li> <li> <p>C#: A2</p> </li> <li> <p>HTML / CSS / JS: A2</p> </li> <li> <p>Lua: A1</p> </li> </ul> <p>Interests:</p> <ul> <li> <p>Go</p> </li> <li> <p>Rust</p> </li> </ul>  Frameworks, software and operating systems  <p>In the following I will go over some of the software and frameworks that I use the most and I have used in my private or university projects.</p> Nvim <p>Recently discovered the power of this text editor and I am currently using it for most of my projects, still trying to get the hang of it though.</p> Zed <p>A more classic IDE written in Rust that I have been using instead of Visual Studio Code for some time now.</p> Git <p>Wouldn't consider myself proficient in the usage of git, but I can use it comfortably to manage my projects and work with other people.</p> LaTeX <p>I have been using LaTeX for many years and for many different projects, again, I would not define myself an expert in the field, but I can use it comfortably to manage all the documents that require a more professional look.</p> Obsidian <p>Discovered this software to take notes and link knowledge and I am trying to integrate it in my workflow in a meaningful way.</p> Goodnotes <p>My number one note taking app on the iPad.</p> Linux <p>I have been a die hard fan of the Linux ecosystem for many years now, I have been using many different distributions (from Void to Debian to Manjaro to Ubuntu) and I always learned something from every time something stopped working.</p> <p>I am currently rocking a single boot Pop-OS! installation of my personal tower with which I do all of my work.</p> Mac OS <p>I have been using a 2014 Macbook Pro since 2022 and I am quite happy with it, I find the operating system amazing and the idea that I can handle all of my packages via terminal through the brew package manager is amazing.</p> Windows <p>I have used Windows for many years, I used to be comfortable with it until I started my university journey, had to switch to Linux to make sure I could work with things like the C compiler and other tools without having to have a headache.</p>"},{"location":"me/erasmus/","title":"Erasmus","text":"<p>During my master studies I decided to try and do an Erasmus experience, due to the hard conditions in which I were during the last years of my bachelor degree I was not in a space in which I could decide to go on an Erasmus adventure. During the master I had the time and the resources to invest in such an experience.</p> <p>I decided to go to Karl Ruprecht university of Heidelberg, in Germany, and due to this increasing grip that I felt wash over me for the physics field I decided to challenge myself with some incredible courses:</p> <ul> <li> <p>Machine learning and Physics - A course about machine learning approaches applied to high energy physics.</p> </li> <li> <p>Astrophysics seminar</p> </li> <li> <p>Condensed Matter</p> </li> <li> <p>Discrete structures 1 - A course about graph theory from the department of mathematics.</p> </li> <li> <p>GPU computing</p> </li> </ul> <p>Due to how hard the exams resulted I ended up with only the Machine learning and Physics exam passed, but the experience completely changed me and taught me many things and forced me to adapt to a changing situation.</p> <p>Let me explain.</p> <p>Heidelberg university does not own student homes, everything is done through an external company called Studierendenwerk Heidelberg, even though the company is completely independent from the university, when the request is sent to receive a place in a student home it's also required of the prospect student to send an email to the university (why? Who knows). If the email is not sent the prospect student is not elegible to receive a place in a student home.</p> <p>Unfortunately the two systems do not talk to each other, therefore if the student doesn't send the email the database from Studierendenwerk will never be notified and said student will be waiting aimlessly for a place in a student home.</p> <p>I was said student.</p> <p>I arrived in Heidelberg on the 29th of september and I began looking for a place using every weapon and technique that I could possibly think of, I asked friend I made at the university, facebook groups and I tried many other solutions. After two, very expensive, weeks in a hostel I was about to wave the white flag and go back to Italy.</p> <p>I tried one last desperate attempt and, incredibly, thanks to a friend (Ujjwal Yadav) that gave me the email of a person that could help me, I was lucky enough to find a place in a student home, even though it was outside of the city.</p> <p>After spending another week at another friend's place I was able to move into my own house that I shared with 3 other people and I could finally start my Erasmus experience.</p> <p></p>"},{"location":"me/passions/","title":"Passions","text":"<p>I have always been easily impressed by people and if I came across anyone with a very strong drive in some area I would easily be captivated and start gaining interest in that area as well, this is why I have tried many different hobbies and, to this day, I have many different interests that I would like to explore further if I had the time.</p>  Movies  <p>Movies are probably one of the things that I like the most, leave me in front of a good TV or at the movie theater and you will find me there. I am trying to build a movie culture that is as broad as possible.</p> <p>My favourite new director is Denis Villeneuve, I think that his movies have an incredible feeling, he is very talented in both directing and photography. My favourite movie of his might be Blade Runner 2049.</p> <p>My favourite old director is Stanley Kubrick, I have seen most of his movies and I do think that his works are simply timeless and will always be relevant and impressive. My favourite movie of his is The Shining.</p>  Climbing  <p>I really like climbing, I have been doing it for around half a year and I feel very comfortable while bouldering, top roping and lead climbing are still another story. I am trying to get better at it and until now I was able to always train between one and two times a week.</p>  Music  <p>I always loved music, I played bass guitar for a couple of years and I would say that I have a good enough musical culture, one of my favourite genres is nu-metal, one of my favourite bands is Linkin Park. Anything progressive, anything industrial, anything more rock or pop-ish is also up my alley.</p> <p></p>  Photography  <p>I have always been fascinated by photography and I am always attracted by the idea of getting a good shot, there was a time when I was very into it and taking a lot of pictures with a Canon Eos 60D, working on the shots and trying to get better at it.</p> <p>I still own a camera, but I do not use it anymore I usually just take pictures with my phone and I take care that the results are as good as they can possibly be. Some of my shots have been chosen to participate in some contests and I have taken pictures for a wedding in 2018.</p>  Reading  <p>I have never been a reader in my life, always struggled with the idea of reading a book, but when I started going to university I built a habit and I found a way of keeping me into the loop. I am surely not the fastest reader, I am not one of those people that can read 50 books a year, but I do enjoy reading and I do it when I can and when I feel like it. Currently trying to read more classics.</p> <p>My favourite book? Hitchhiker's Guide to the Galaxy, by Douglas Adams.</p>"},{"location":"me/podcast/","title":"Overhear podcast","text":"<p>At the end of 2021 me and my good friend Alin Tomulet decided to start a joint project to talk about cool stuff on the air. I always wanted to do something radio-like but all the previous projects I tried did non work out.</p> <p>We started recording episodes in my room and we were able to start inviting some friends over as guests after just a couple of episodes. All of the episodes were around the hour mark and we usually talked about topics that were in the field of technology, startups and innovation. We invited people like Alessandro Risaro co-founder of the DataPizza startup, that is trying to create a connection between the italian tech industry and workers.</p> <p>After around a year of recording and 10 episodes published we decided to merge with another podcast, that can still be found on Spotify. OVERHEAR is a podcast that has been going on and off for a couple of years and was originally held by Tommaso Lucarelli, Stefano Frosi and Emanuele Baldelli, we came around for the fourth season of the podcast and we recorded a series of episodes with them, inviting professors some of the professors of the university of Milano (Paolo Boldi, Sebastiano Vigna, Christian Quadri) among others.</p> <p>Due to everyone in the group having different goals and different schedules unfortunately we had to stop the production of the podcast, but it was an amazing experience and an opportunity to do something great together with very talented people.</p>"},{"location":"me/polimi/","title":"Polytechnic university of Milan","text":"<p>I began my bachelor studies pursuing a degree in Computer engineering at the Polytechnic University of Milan. Unfortunately, due to the covid pandemic in 2020 and family hardships I chose to stop my studies there and to pursue them in some other university.</p> <p>During the first two years of studying I went through the following exams:</p> <ul> <li> <p>Calculus 1 and 2</p> </li> <li> <p>Algebra</p> </li> <li> <p>Advanced algebra and logic</p> </li> <li> <p>Foundamentals of Computer Science</p> </li> <li> <p>Architectures and Operating systems</p> </li> <li> <p>Foundamentals of control systems</p> </li> <li> <p>Physics 1</p> </li> <li> <p>Chemistry</p> </li> <li> <p>Algorithms and Data structures</p> </li> </ul>"},{"location":"me/unimi/","title":"University of Milan","text":"<p>I began my master in Computer Science at the University of Milan in September 2022 wanting to focus on web development, distributed systems and cloud technologies.</p> <p>After some time I discovered the existence of other fields, like machine learning, and I fell in love with the idea of finally applying computer science as an instrument to support research in other fields. I started my thesis in September 2024 and it's titled \"Supervised machine learning techniques for quench detecction in superconductors\" followed by professor Dario Malchiodi and Lucio Rossi.</p> <p>My university curriculum is a mix of theoretical computer science, with the following courses:</p> <ul> <li> <p>Algoritmi e complessit\u00e0 (Algorithms and Complexity) - A course about advanced algorithms.</p> </li> <li> <p>Metodi probabilistici per l'informatica (Probabilistic methods for computer science) - A course about Markov Chains and their applications.</p> </li> <li> <p>Algoritmica per il web (web algorithmics) - A course about the latest technologies in the field of web algorithmics.</p> </li> <li> <p>Heuristic Algorithms - A course about heuristic and metaheuristic algorithms.</p> </li> </ul> <p>distributed systems, with the following courses:</p> <ul> <li> <p>Distributed and pervasive systems</p> </li> <li> <p>GPU computing</p> </li> <li> <p>Cloud computing Technologies</p> </li> </ul> <p>and some other misc courses like:</p> <ul> <li> <p>Calcolo numerico (Numerical Analysis) - A course about numerical methods for solving various problems.</p> </li> <li> <p>Reti wireless and mobili (Mobile and wireless networks)</p> </li> <li> <p>Fisica degli acceleratori 1 (Accelerator physics 1)</p> </li> <li> <p>Artificial intelligence</p> </li> <li> <p>Videogame design and programming</p> </li> </ul>"},{"location":"me/unimib/","title":"University of Milan Bicocca","text":"<p>I finished my bachelor with a degree in computer science at the University of Milano Bicocca in 2022. I graduated with 102/110 with a thesis about the project that I did with a colleague for Certimeter group, a Torino based company. During the studies I went through the following exams:</p> <ul> <li> <p>Foundamentals of algebra</p> </li> <li> <p>Programming 1 and 2 - Java programming</p> </li> <li> <p>C++ programming</p> </li> <li> <p>Algorithms 1 and 2 - Basic algorithms and basic graph algorithms</p> </li> <li> <p>Programming languages - a course about programming in languages employing different paradigms (Common lisp and Prolog)</p> </li> <li> <p>Distributed systems</p> </li> <li> <p>Operations research</p> </li> <li> <p>Computer security</p> </li> <li> <p>Probability and statistics</p> </li> <li> <p>Database</p> </li> <li> <p>Software engineering</p> </li> </ul>"},{"location":"structures/readme/","title":"Discrete structures 1","text":"<p>The project can be found on GitHub (Discrete Structures 1 project)</p>  Introduction  <p>The idea behind this project was to provide students with an open source version of the notes for the course of Discrete Structures 1 held by professor Bertille and professor Joos at university Karl Ruprecht of Heidelberg, the notes are in english and have not been updated since the beginning of this year.</p> <p>These notes are currently undergoing some maintenance, therefore the last pdf version is not in the best shape, a future release is bound to fix its appearance. The latest version of the notes can be downloaded at the link below.</p> <p>Download DS1 notes</p>"},{"location":"vdp/readme/","title":"Pump down the flame","text":"<p>The original project page with the download links can be found here Polimi Game Collective.</p> <p>Pump down the flame was a project I developed alongside Federico Maglione, Fabio Patella and Nicol\u00f2 Fasulo to participate in the 2022 Videogame Design and Development course. The game was a 2d level-based platformer in which the objective was to save a series of hostages before the time ran out and without dying.</p> <p>The game was developed using Unity and the sprites were a mix of free asstes and assets created using midjourney and stable diffusion. The game was developed in a span of circa 3 months and was one of the most appreciated games of the course gaining us an overall 6th place out of 24 games and a final grade of 27/30.</p>"}]}